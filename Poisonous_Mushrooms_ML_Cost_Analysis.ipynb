{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt2juUAdjB1pk1qFJFGL85",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielomara/K-Means-Analysis/blob/main/Poisonous_Mushrooms_ML_Cost_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krIG0mZ4BlpM",
        "outputId": "e0d03787-22ea-4b46-de2b-46f779d841ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset\n",
        "mushroom = fetch_ucirepo(id=73)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "k = mushroom.data.features\n",
        "f = mushroom.data.targets\n",
        "\n",
        "#copy the data to allow for changing the dataset\n",
        "x = pd.DataFrame(k)\n",
        "y = pd.DataFrame(f)\n",
        "\n",
        "# metadata\n",
        "mushroom.metadata\n",
        "\n",
        "# variable information\n",
        "mushroom.variables\n",
        "\n",
        "#create a df combining poisonous with variables to have an overview of the table\n",
        "df = pd.concat([x, y], axis=1)"
      ],
      "metadata": {
        "id": "6gZjhuMDBtHb"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 & 3"
      ],
      "metadata": {
        "id": "wr-tXtQXGpYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to replace missing values with the most probable option\n",
        "def fill_missing_values():\n",
        "    l = x.columns\n",
        "    for i in l:\n",
        "        most = x[i].value_counts().idxmax()\n",
        "        x[i] = x[i].fillna(most)\n",
        "\n",
        "fill_missing_values()"
      ],
      "metadata": {
        "id": "4B9uflwSTJVI"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove variables that don't appear more than 1/10 of instances and replace with a representative distribution\n",
        "def remove_rare():\n",
        "    l = x.columns\n",
        "    for i in l:\n",
        "        value_counts = x[i].value_counts()\n",
        "        for value, count in value_counts.items():\n",
        "            # Check if the count is less than or equal to 813 (1/10th of instances)\n",
        "            if count <= 813:\n",
        "                # Replace the rare value with the most frequent value\n",
        "                most = x[i].value_counts().idxmax()\n",
        "                x[i] = x[i].replace(value, most)\n",
        "\n",
        "remove_rare()"
      ],
      "metadata": {
        "id": "_thPTnWUCf5t"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign each variable a numerical value as opposed to categorical\n",
        "for column_name in x.columns:\n",
        "    x[column_name] = x[column_name].astype('category')\n",
        "    x[column_name] = x[column_name].cat.codes"
      ],
      "metadata": {
        "id": "h0JZSlcQY31T"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:\n",
        "Considering a specific business setting...**\n",
        "\n",
        "Indeed, the market for rare mushrooms is niche, however if one was to be the first to find and cultivate a new species of mushroom it could be a profitable endeavour.\n",
        "\n",
        "Yet we would have to be sure that the mushroom was edible before trying it ourselves. In this case, it would be good to have a model that could predict whether or not it was edible. As the costs of making a mistake here could be deadly."
      ],
      "metadata": {
        "id": "Sjs_OoXH1kCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: False positives and negatives...**\n",
        "\n",
        "In this scenario the cost of false negatives are incredibly high and may be a question of life or death.\n",
        "\n",
        "In the case that you were to pick and eat a mushroom that was a false negative, you would be eating something poisonous, with effects ranging from stomach discomfort, nerve damage and possibly death. Leading to very high medical bills or even legal issues.\n",
        "\n",
        "On the other hand, if a false positive was produced the effects would be rather benign as the mushroom would not be eaten regardless. Indeed there is an opportunity cost that must be considered in the case of false positives as it could be that the mushroom would otherwise sell well and be a profitable fungi to cultivate, something which would not happen if the mushroom wasn't falsely labelled as \"poisonous\".\n",
        "\n",
        "**Cost Ratio**\n",
        "\n",
        "I estimate that the cost of a false negative is around 1,000 times higher than that of a false positive.\n",
        "\n",
        "Due to the potential deadly consequences, high medical fees and legal damages that could be incurred, vs the lost mushroom which I calculate at â‚¬10 (adding a little to account for the opportunity cost of picking the mushroom and potential commercial potential).\n",
        "\n",
        "For that reason the ratio is 1,000:1. Implying that false negatives incur a seriously higher cost than false positives."
      ],
      "metadata": {
        "id": "O1yf-gSj4n_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6 function to calculate the costs of prediction\n",
        "def calculate_cost(y_actual, y_pred):\n",
        "    cost_FP = 0\n",
        "    cost_FN = 0\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_pred[i] == 'p' and y_actual.iloc[i]['poisonous'] == 'e':\n",
        "            cost_FP += 10\n",
        "        elif y_pred[i] == 'e' and y_actual.iloc[i]['poisonous'] == 'p':\n",
        "            cost_FN += 10000\n",
        "    cost = cost_FN + cost_FP\n",
        "    return cost"
      ],
      "metadata": {
        "id": "l_bNhz6JxhKL"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 7 creating candidate thresholds for mapping probabilities to predictions\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100)\n"
      ],
      "metadata": {
        "id": "H0qkugjKt8JE"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 8 creating a matrix of 100,10 with zero values\n",
        "\n",
        "out = np.zeros((100,10))\n"
      ],
      "metadata": {
        "id": "BhAM4xolINNM"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 9 creating fold_vec\n",
        "n = np.ceil(len(y) / 10)\n",
        "fold_vec = np.concatenate([np.arange(1, 11)] * int(n))\n",
        "fold_vec = fold_vec[0:len(y)]\n",
        "np.random.seed(1)\n",
        "fold_vec = np.random.permutation(fold_vec)\n"
      ],
      "metadata": {
        "id": "NqDUPQSGJHyh"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 10 logistical regression and prediction cost for candidate thresholds\n",
        "\n",
        "for i in range(10):\n",
        "    # Determine the test and train indices\n",
        "    test_i = np.where(fold_vec == i + 1)\n",
        "    train_i = np.where(fold_vec != i + 1)\n",
        "\n",
        "    #split data into training and testing sets\n",
        "    x_train = x.iloc[train_i]\n",
        "    y_train = y.iloc[train_i]\n",
        "    x_test = x.iloc[test_i]\n",
        "    y_test = y.iloc[test_i]\n",
        "\n",
        "    #initialize and fit the logistic regression model\n",
        "    mod = LogisticRegression(max_iter=1000)\n",
        "    mod.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "    #predict probabilities for the test set\n",
        "    y_pred_prob = mod.predict_proba(x_test)[:, 1]\n",
        "\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = ['p' if prob >= threshold else 'e' for prob in y_pred_prob]\n",
        "        out[j, i] = calculate_cost(y_test, y_pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gxYqyibdOUyH"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 11 determine the threshold with the best performance and its associated cost\n",
        "# Calculate the row-wise sum using np.apply_along_axis\n",
        "row_sums = np.apply_along_axis(np.sum, axis=1, arr=out)\n",
        "\n",
        "# Find the index of the minimum sum\n",
        "min_index = np.argmin(row_sums)\n",
        "\n",
        "# Extract the best threshold and cost\n",
        "best_threshold = thresholds[min_index]\n",
        "best_cost = row_sums[min_index]\n",
        "\n",
        "print(f\" the best cost is {best_cost}, with a threshold of {best_threshold}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwUy7ntpOQ0x",
        "outputId": "3531a92b-2e5f-4425-db17-a3401f406c21"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the best cost is 8480.0, with a threshold of 0.05050505050505051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 12**\n",
        "\n",
        "It is clear that givent the high cost of false negatives, the very low threshold of 0.05 leads to the lowest cost.\n",
        "\n",
        "For this reason I will redfine the threshold to hone in a more exact value at the lower end of the threshold scale."
      ],
      "metadata": {
        "id": "KH9piCtSlzNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Refining thresholds:\n",
        "thresholds2 = np.linspace(0, 0.1, 100)"
      ],
      "metadata": {
        "id": "ePVMYgiVmUCT"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create new out to store cost values for each test threshold\n",
        "out2 = np.zeros((100,10))"
      ],
      "metadata": {
        "id": "rzpT5Bcqnodi"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate new costs for each new threshold and store it in \"out2\"\n",
        "for i in range(10):\n",
        "    # Determine the test and train indices\n",
        "    test_i = np.where(fold_vec == i + 1)\n",
        "    train_i = np.where(fold_vec != i + 1)\n",
        "\n",
        "    #split data into training and testing sets\n",
        "    x_train = x.iloc[train_i]\n",
        "    y_train = y.iloc[train_i]\n",
        "    x_test = x.iloc[test_i]\n",
        "    y_test = y.iloc[test_i]\n",
        "\n",
        "    #initialize and fit the logistic regression model\n",
        "    mod = LogisticRegression(max_iter=1000)\n",
        "    mod.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "    #predict probabilities for the test set\n",
        "    y_pred_prob = mod.predict_proba(x_test)[:, 1]\n",
        "\n",
        "    for j, threshold in enumerate(thresholds2):\n",
        "        y_pred = ['p' if prob >= threshold else 'e' for prob in y_pred_prob]\n",
        "        out2[j, i] = calculate_cost(y_test, y_pred)"
      ],
      "metadata": {
        "id": "TxgdaUevn28v"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate new cost with refined thresholds:\n",
        "\n",
        "row_sums2 = np.apply_along_axis(np.sum, axis=1, arr=out2)\n",
        "\n",
        "# Find the index of the minimum sum\n",
        "min_index = np.argmin(row_sums2)\n",
        "\n",
        "# Extract the best threshold and cost\n",
        "best_threshold_refined = thresholds2[min_index]\n",
        "best_cost_refined = row_sums2[min_index]\n",
        "\n",
        "print(\"Best Threshold (Refined):\", best_threshold_refined)\n",
        "print(\"Best Cost (Refined):\", best_cost_refined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCdwzwHipDyk",
        "outputId": "a63761b4-e1bc-4f01-e32d-7c989cfadc20"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold (Refined): 0.05454545454545454\n",
            "Best Cost (Refined): 8180.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see above that with the refined threshold of 0.0545, our cost has decreased everso slightly to 8180 from 8480."
      ],
      "metadata": {
        "id": "fAFUSgURrZwZ"
      }
    }
  ]
}